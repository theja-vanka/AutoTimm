{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Interpretation Tutorial\n",
    "\n",
    "This notebook provides a complete guide to using AutoTimm's interpretation capabilities.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Interpretation Methods** - 6 different explanation techniques\n",
    "2. **Quality Metrics** - Quantitative evaluation of explanations\n",
    "3. **Interactive Visualizations** - Plotly-based exploration tools\n",
    "4. **Performance Optimization** - Caching, batching, and profiling\n",
    "5. **Production Best Practices** - Real-world deployment tips\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install autotimm[all]  # Includes plotly for interactive visualizations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# AutoTimm imports\n",
    "from autotimm import ImageClassifier\n",
    "from autotimm.interpretation import (\n",
    "    GradCAM,\n",
    "    GradCAMPlusPlus,\n",
    "    IntegratedGradients,\n",
    "    SmoothGrad,\n",
    "    AttentionRollout,\n",
    "    AttentionFlow,\n",
    "    quick_explain,\n",
    "    compare_methods,\n",
    "    ExplanationMetrics,\n",
    "    InteractiveVisualizer,\n",
    "    ExplanationCache,\n",
    "    BatchProcessor,\n",
    "    PerformanceProfiler,\n",
    "    optimize_for_inference,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Load Model and Data\n",
    "\n",
    "We'll use a pre-trained ResNet model for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model = ImageClassifier(\n",
    "    backbone=\"resnet50\",\n",
    "    num_classes=10,\n",
    "    pretrained=False  # Set True if you have pre-trained weights\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Backbone: resnet50\")\n",
    "print(f\"Number of classes: 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample images for demonstration\n",
    "def create_sample_image(seed=42, size=(224, 224)):\n",
    "    \"\"\"Create a random sample image.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    img_array = np.random.rand(size[0], size[1], 3)\n",
    "    img_array = (img_array * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "# Create test image\n",
    "test_image = create_sample_image(seed=42)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_image)\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {test_image.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Start: Simplest Way to Explain\n",
    "\n",
    "The fastest way to get an explanation is using `quick_explain()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick explanation with default settings\n",
    "fig = quick_explain(\n",
    "    model,\n",
    "    test_image,\n",
    "    method=\"gradcam\",\n",
    "    show_plot=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Quick explanation generated!\")\n",
    "print(\"  This shows which parts of the image the model focuses on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpretation Methods: Deep Dive\n",
    "\n",
    "AutoTimm provides 6 different interpretation methods. Let's explore each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GradCAM (Gradient-weighted Class Activation Mapping)\n",
    "\n",
    "**How it works:** Uses gradients flowing into the final convolutional layer to highlight important regions.\n",
    "\n",
    "**Best for:** General-purpose visualization, CNNs\n",
    "\n",
    "**Pros:** Fast, interpretable, works well for most CNNs\n",
    "\n",
    "**Cons:** Limited to convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradCAM\n",
    "gradcam = GradCAM(model)\n",
    "\n",
    "# Generate explanation\n",
    "heatmap_gradcam = gradcam.explain(\n",
    "    test_image,\n",
    "    target_class=5  # Explain prediction for class 5\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "gradcam.visualize(\n",
    "    test_image,\n",
    "    heatmap_gradcam,\n",
    "    alpha=0.6,\n",
    "    title=\"GradCAM Explanation\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Heatmap shape: {heatmap_gradcam.shape}\")\n",
    "print(f\"Value range: [{heatmap_gradcam.min():.3f}, {heatmap_gradcam.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GradCAM++ (Improved GradCAM)\n",
    "\n",
    "**How it works:** Enhanced version of GradCAM with better localization for multiple objects.\n",
    "\n",
    "**Best for:** Images with multiple objects, better localization\n",
    "\n",
    "**Pros:** Better than GradCAM for multiple objects\n",
    "\n",
    "**Cons:** Slightly slower than GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradCAM++\n",
    "gradcam_pp = GradCAMPlusPlus(model)\n",
    "\n",
    "# Generate explanation\n",
    "heatmap_gradcam_pp = gradcam_pp.explain(test_image, target_class=5)\n",
    "\n",
    "# Visualize\n",
    "gradcam_pp.visualize(\n",
    "    test_image,\n",
    "    heatmap_gradcam_pp,\n",
    "    alpha=0.6,\n",
    "    title=\"GradCAM++ Explanation\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Integrated Gradients\n",
    "\n",
    "**How it works:** Integrates gradients along a path from a baseline to the input.\n",
    "\n",
    "**Best for:** Pixel-level attributions, research\n",
    "\n",
    "**Pros:** Theoretically sound, satisfies axioms\n",
    "\n",
    "**Cons:** Slower, requires baseline selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Integrated Gradients\n",
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# Generate explanation (this may take longer)\n",
    "print(\"Computing Integrated Gradients (may take 10-20 seconds)...\")\n",
    "heatmap_ig = ig.explain(\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    n_steps=50  # Number of integration steps (more = better but slower)\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "ig.visualize(\n",
    "    test_image,\n",
    "    heatmap_ig,\n",
    "    alpha=0.6,\n",
    "    title=\"Integrated Gradients Explanation\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Integrated Gradients complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 SmoothGrad\n",
    "\n",
    "**How it works:** Averages gradients over multiple noisy versions of the input.\n",
    "\n",
    "**Best for:** Reducing noise in gradient-based explanations\n",
    "\n",
    "**Pros:** Smoother, more stable explanations\n",
    "\n",
    "**Cons:** Slower (requires multiple forward passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SmoothGrad\n",
    "smoothgrad = SmoothGrad(model)\n",
    "\n",
    "# Generate explanation\n",
    "print(\"Computing SmoothGrad (may take 10-20 seconds)...\")\n",
    "heatmap_smoothgrad = smoothgrad.explain(\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    n_samples=50,  # Number of noisy samples\n",
    "    noise_level=0.15  # Standard deviation of noise\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "smoothgrad.visualize(\n",
    "    test_image,\n",
    "    heatmap_smoothgrad,\n",
    "    alpha=0.6,\n",
    "    title=\"SmoothGrad Explanation\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì SmoothGrad complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 & 3.6 Attention Methods (Vision Transformers)\n",
    "\n",
    "**AttentionRollout** and **AttentionFlow** are designed for Vision Transformers (ViT).\n",
    "\n",
    "Since our example uses ResNet (CNN), we'll skip these for now. They work similarly but require a Transformer-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing Methods Side-by-Side\n",
    "\n",
    "Let's compare multiple methods visually using `compare_methods()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple methods\n",
    "fig = compare_methods(\n",
    "    model,\n",
    "    test_image,\n",
    "    methods=[\"gradcam\", \"gradcam++\"],  # Add more: \"integrated_gradients\", \"smoothgrad\"\n",
    "    target_class=5,\n",
    "    figsize=(12, 4)\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Method comparison complete!\")\n",
    "print(\"  Notice the differences in highlighted regions between methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explanation Quality Metrics\n",
    "\n",
    "How do we know if an explanation is good? Use quantitative metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "metrics = ExplanationMetrics(model, gradcam)\n",
    "\n",
    "print(\"Computing explanation quality metrics...\")\n",
    "print(\"This may take 1-2 minutes...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Deletion Metric (Faithfulness)\n",
    "\n",
    "**What it measures:** How much does the prediction drop when we remove important pixels?\n",
    "\n",
    "**Interpretation:** Higher drop = more faithful explanation\n",
    "\n",
    "**Expected:** Good explanations cause large prediction drops when important regions are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion metric\n",
    "deletion_result = metrics.deletion(\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    steps=20  # Number of deletion steps\n",
    ")\n",
    "\n",
    "print(\"Deletion Metric Results:\")\n",
    "print(f\"  AUC: {deletion_result['auc']:.4f}\")\n",
    "print(f\"  Final drop: {deletion_result['final_drop']:.4f}\")\n",
    "print(f\"\\n  Interpretation: Lower AUC = better (faster drop in prediction)\")\n",
    "\n",
    "# Plot deletion curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(deletion_result['scores'], marker='o')\n",
    "plt.xlabel('Deletion Step')\n",
    "plt.ylabel('Prediction Score')\n",
    "plt.title('Deletion Curve (Should Decrease)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Insertion Metric (Faithfulness)\n",
    "\n",
    "**What it measures:** How much does the prediction rise when we progressively add important pixels?\n",
    "\n",
    "**Interpretation:** Faster rise = more faithful explanation\n",
    "\n",
    "**Expected:** Good explanations cause rapid prediction increases when important regions are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion metric\n",
    "insertion_result = metrics.insertion(\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    steps=20\n",
    ")\n",
    "\n",
    "print(\"Insertion Metric Results:\")\n",
    "print(f\"  AUC: {insertion_result['auc']:.4f}\")\n",
    "print(f\"  Final rise: {insertion_result['final_rise']:.4f}\")\n",
    "print(f\"\\n  Interpretation: Higher AUC = better (faster rise in prediction)\")\n",
    "\n",
    "# Plot insertion curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(insertion_result['scores'], marker='o', color='green')\n",
    "plt.xlabel('Insertion Step')\n",
    "plt.ylabel('Prediction Score')\n",
    "plt.title('Insertion Curve (Should Increase)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Sensitivity-N (Stability)\n",
    "\n",
    "**What it measures:** How stable is the explanation under small input perturbations?\n",
    "\n",
    "**Interpretation:** Lower sensitivity = more stable explanation\n",
    "\n",
    "**Expected:** Good explanations shouldn't change drastically with tiny noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity metric\n",
    "print(\"Computing sensitivity (may take 20-30 seconds)...\")\n",
    "sensitivity_result = metrics.sensitivity_n(\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    n_samples=20,  # Number of noisy samples\n",
    "    noise_level=0.15\n",
    ")\n",
    "\n",
    "print(\"\\nSensitivity-N Results:\")\n",
    "print(f\"  Sensitivity: {sensitivity_result['sensitivity']:.4f}\")\n",
    "print(f\"  Std deviation: {sensitivity_result['std']:.4f}\")\n",
    "print(f\"  Max change: {sensitivity_result['max_change']:.4f}\")\n",
    "print(f\"\\n  Interpretation: Lower values = more stable explanation\")\n",
    "\n",
    "# Plot sensitivity distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(sensitivity_result['changes'], bins=15, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Explanation Change')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Explanation Changes Under Noise')\n",
    "plt.axvline(sensitivity_result['sensitivity'], color='red', \n",
    "           linestyle='--', label=f\"Mean: {sensitivity_result['sensitivity']:.3f}\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Sanity Checks\n",
    "\n",
    "Two sanity checks ensure explanations are meaningful:\n",
    "\n",
    "1. **Model Parameter Randomization**: Explanation should change with randomized model\n",
    "2. **Data Randomization**: Explanation should differ for different target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter randomization test\n",
    "param_test = metrics.model_parameter_randomization_test(\n",
    "    test_image,\n",
    "    target_class=5\n",
    ")\n",
    "\n",
    "print(\"Model Parameter Randomization Test:\")\n",
    "print(f\"  Correlation with randomized model: {param_test['correlation']:.4f}\")\n",
    "print(f\"  Change: {param_test['change']:.4f}\")\n",
    "print(f\"  Passes: {param_test['passes']}\")\n",
    "print(f\"\\n  ‚úì Should PASS: Explanation changes with random model\")\n",
    "\n",
    "# Data randomization test\n",
    "data_test = metrics.data_randomization_test(\n",
    "    test_image,\n",
    "    target_class=5\n",
    ")\n",
    "\n",
    "print(\"\\nData Randomization Test:\")\n",
    "print(f\"  Correlation with different class: {data_test['correlation']:.4f}\")\n",
    "print(f\"  Change: {data_test['change']:.4f}\")\n",
    "print(f\"  Passes: {data_test['passes']}\")\n",
    "print(f\"\\n  ‚úì Should PASS: Explanation differs for different classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Pointing Game (Localization)\n",
    "\n",
    "**What it measures:** Does the maximum attention fall within the ground-truth bounding box?\n",
    "\n",
    "**Interpretation:** Hit = good localization\n",
    "\n",
    "**Note:** Requires ground-truth bounding boxes (we'll simulate one here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a bounding box (x1, y1, x2, y2)\n",
    "bbox = (50, 50, 150, 150)  # Example bbox\n",
    "\n",
    "# Pointing game\n",
    "pointing_result = metrics.pointing_game(\n",
    "    test_image,\n",
    "    bbox,\n",
    "    target_class=5\n",
    ")\n",
    "\n",
    "print(\"Pointing Game Results:\")\n",
    "print(f\"  Hit: {pointing_result['hit']}\")\n",
    "print(f\"  Max location: {pointing_result['max_location']}\")\n",
    "print(f\"  Bounding box: {pointing_result['bbox']}\")\n",
    "print(f\"\\n  Interpretation: Hit = max attention inside bbox\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(heatmap_gradcam, cmap='jet', alpha=0.6)\n",
    "ax.imshow(test_image, alpha=0.4)\n",
    "\n",
    "# Draw bbox\n",
    "from matplotlib.patches import Rectangle\n",
    "rect = Rectangle(\n",
    "    (bbox[0], bbox[1]), \n",
    "    bbox[2] - bbox[0], \n",
    "    bbox[3] - bbox[1],\n",
    "    linewidth=2, \n",
    "    edgecolor='green', \n",
    "    facecolor='none'\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# Mark max location\n",
    "ax.plot(\n",
    "    pointing_result['max_location'][1], \n",
    "    pointing_result['max_location'][0], \n",
    "    'r*', \n",
    "    markersize=15, \n",
    "    label='Max Attention'\n",
    ")\n",
    "\n",
    "ax.set_title('Pointing Game: Max Attention vs Ground Truth')\n",
    "ax.legend()\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Metrics Summary\n",
    "\n",
    "Let's compile all metrics into a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics summary\n",
    "import pandas as pd\n",
    "\n",
    "metrics_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Metric': 'Deletion AUC',\n",
    "        'Value': f\"{deletion_result['auc']:.4f}\",\n",
    "        'Interpretation': 'Lower = better',\n",
    "        'Category': 'Faithfulness'\n",
    "    },\n",
    "    {\n",
    "        'Metric': 'Insertion AUC',\n",
    "        'Value': f\"{insertion_result['auc']:.4f}\",\n",
    "        'Interpretation': 'Higher = better',\n",
    "        'Category': 'Faithfulness'\n",
    "    },\n",
    "    {\n",
    "        'Metric': 'Sensitivity-N',\n",
    "        'Value': f\"{sensitivity_result['sensitivity']:.4f}\",\n",
    "        'Interpretation': 'Lower = better',\n",
    "        'Category': 'Stability'\n",
    "    },\n",
    "    {\n",
    "        'Metric': 'Model Param Test',\n",
    "        'Value': 'PASS' if param_test['passes'] else 'FAIL',\n",
    "        'Interpretation': 'Should pass',\n",
    "        'Category': 'Sanity Check'\n",
    "    },\n",
    "    {\n",
    "        'Metric': 'Data Randomization',\n",
    "        'Value': 'PASS' if data_test['passes'] else 'FAIL',\n",
    "        'Interpretation': 'Should pass',\n",
    "        'Category': 'Sanity Check'\n",
    "    },\n",
    "    {\n",
    "        'Metric': 'Pointing Game',\n",
    "        'Value': 'HIT' if pointing_result['hit'] else 'MISS',\n",
    "        'Interpretation': 'Hit = good',\n",
    "        'Category': 'Localization'\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPLANATION QUALITY METRICS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(metrics_summary.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Visualizations\n",
    "\n",
    "Static images are great, but interactive visualizations let you explore in detail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if plotly is available\n",
    "try:\n",
    "    viz = InteractiveVisualizer(model)\n",
    "    print(\"‚úì Interactive visualizations available!\")\n",
    "    INTERACTIVE_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Interactive visualizations not available: {e}\")\n",
    "    print(\"  Install with: pip install plotly\")\n",
    "    INTERACTIVE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Basic Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_AVAILABLE:\n",
    "    # Create interactive visualization\n",
    "    fig = viz.visualize_explanation(\n",
    "        test_image,\n",
    "        gradcam,\n",
    "        target_class=5,\n",
    "        title=\"Interactive GradCAM\",\n",
    "        colorscale=\"Viridis\",\n",
    "        opacity=0.6,\n",
    "        save_path=\"tutorial_interactive.html\"\n",
    "    )\n",
    "    \n",
    "    # Display in notebook\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n‚úì Interactive visualization created!\")\n",
    "    print(\"  Try: Zoom (scroll), Pan (drag), Hover (see values)\")\n",
    "    print(\"  Saved to: tutorial_interactive.html\")\n",
    "else:\n",
    "    print(\"Skipping interactive visualizations (plotly not installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Method Comparison (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_AVAILABLE:\n",
    "    # Compare methods interactively\n",
    "    explainers = {\n",
    "        'GradCAM': gradcam,\n",
    "        'GradCAM++': gradcam_pp,\n",
    "    }\n",
    "    \n",
    "    fig = viz.compare_methods(\n",
    "        test_image,\n",
    "        explainers,\n",
    "        target_class=5,\n",
    "        title=\"Interactive Method Comparison\",\n",
    "        save_path=\"tutorial_comparison.html\",\n",
    "        width=1400,\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n‚úì Interactive comparison created!\")\n",
    "    print(\"  Saved to: tutorial_comparison.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Comprehensive HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_AVAILABLE:\n",
    "    # Generate comprehensive report\n",
    "    report_path = viz.create_report(\n",
    "        test_image,\n",
    "        gradcam,\n",
    "        target_class=5,\n",
    "        include_statistics=True,\n",
    "        save_path=\"tutorial_report.html\",\n",
    "        title=\"Model Interpretation Report\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì Comprehensive report created!\")\n",
    "    print(f\"  Saved to: {report_path}\")\n",
    "    print(f\"  Open in browser to view full report with:\")\n",
    "    print(f\"    - Prediction information\")\n",
    "    print(f\"    - Top-5 classes\")\n",
    "    print(f\"    - Heatmap statistics\")\n",
    "    print(f\"    - Interactive visualization\")\n",
    "    print(f\"    - Distribution plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Optimization\n",
    "\n",
    "For production systems, speed matters! Let's optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Caching for Repeated Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cache\n",
    "cache = ExplanationCache(\n",
    "    cache_dir=\"./tutorial_cache\",\n",
    "    max_size_mb=100,  # 100 MB cache\n",
    "    enabled=True\n",
    ")\n",
    "\n",
    "# Without caching\n",
    "print(\"Without caching:\")\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    heatmap = gradcam.explain(test_image, target_class=5)\n",
    "time_no_cache = time.time() - start\n",
    "print(f\"  5 explanations: {time_no_cache:.3f}s ({time_no_cache/5:.3f}s each)\")\n",
    "\n",
    "# With caching\n",
    "print(\"\\nWith caching:\")\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    # Check cache\n",
    "    heatmap = cache.get(test_image, method=\"gradcam\", target_class=5)\n",
    "    if heatmap is None:\n",
    "        # Cache miss - compute and store\n",
    "        heatmap = gradcam.explain(test_image, target_class=5)\n",
    "        cache.put(test_image, method=\"gradcam\", explanation=heatmap, target_class=5)\n",
    "time_with_cache = time.time() - start\n",
    "print(f\"  5 explanations: {time_with_cache:.3f}s ({time_with_cache/5:.3f}s each)\")\n",
    "\n",
    "# Speedup\n",
    "speedup = time_no_cache / time_with_cache\n",
    "print(f\"\\n‚úì Speedup: {speedup:.1f}x faster with caching!\")\n",
    "\n",
    "# Cache statistics\n",
    "stats = cache.stats()\n",
    "print(f\"\\nCache stats:\")\n",
    "print(f\"  Entries: {stats['num_entries']}\")\n",
    "print(f\"  Size: {stats['total_size_mb']:.2f} MB\")\n",
    "print(f\"  Utilization: {stats['utilization']:.1%}\")\n",
    "\n",
    "# Cleanup\n",
    "cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple test images\n",
    "test_images = [create_sample_image(seed=i) for i in range(20)]\n",
    "\n",
    "# Sequential processing\n",
    "print(\"Sequential processing (one-by-one):\")\n",
    "start = time.time()\n",
    "heatmaps_seq = [gradcam.explain(img) for img in test_images]\n",
    "time_seq = time.time() - start\n",
    "print(f\"  20 images: {time_seq:.3f}s ({time_seq/20:.3f}s per image)\")\n",
    "\n",
    "# Batch processing\n",
    "print(\"\\nBatch processing:\")\n",
    "processor = BatchProcessor(\n",
    "    model,\n",
    "    gradcam,\n",
    "    batch_size=8,\n",
    "    show_progress=False,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "heatmaps_batch = processor.process_batch(test_images)\n",
    "time_batch = time.time() - start\n",
    "print(f\"  20 images: {time_batch:.3f}s ({time_batch/20:.3f}s per image)\")\n",
    "\n",
    "# Speedup\n",
    "speedup = time_seq / time_batch\n",
    "print(f\"\\n‚úì Speedup: {speedup:.1f}x faster with batching!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Performance Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create profiler\n",
    "profiler = PerformanceProfiler(enabled=True)\n",
    "\n",
    "# Profile interpretation pipeline\n",
    "with profiler.profile(\"total\"):\n",
    "    with profiler.profile(\"preprocessing\"):\n",
    "        # Simulate preprocessing\n",
    "        tensor = torch.from_numpy(np.array(test_image)).permute(2, 0, 1).float() / 255.0\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "    \n",
    "    with profiler.profile(\"forward_pass\"):\n",
    "        with torch.no_grad():\n",
    "            output = model(tensor)\n",
    "    \n",
    "    with profiler.profile(\"explanation\"):\n",
    "        heatmap = gradcam.explain(test_image, target_class=5)\n",
    "    \n",
    "    with profiler.profile(\"postprocessing\"):\n",
    "        normalized = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "\n",
    "# Print statistics\n",
    "profiler.print_stats()\n",
    "\n",
    "# Identify bottleneck\n",
    "stats = profiler.get_stats()\n",
    "slowest = max(stats.items(), key=lambda x: x[1]['mean'])\n",
    "print(f\"\\n‚ö† Bottleneck: {slowest[0]} ({slowest[1]['mean']:.3f}s)\")\n",
    "print(f\"  Focus optimization efforts here!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark original model\n",
    "print(\"Original model:\")\n",
    "tensor = torch.from_numpy(np.array(test_image)).permute(2, 0, 1).float() / 255.0\n",
    "tensor = tensor.unsqueeze(0)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "time_original = time.time() - start\n",
    "print(f\"  10 forward passes: {time_original:.3f}s ({time_original/10:.3f}s each)\")\n",
    "\n",
    "# Optimize model\n",
    "model_opt = optimize_for_inference(model, use_fp16=False)\n",
    "\n",
    "# Benchmark optimized model\n",
    "print(\"\\nOptimized model:\")\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        output = model_opt(tensor)\n",
    "time_optimized = time.time() - start\n",
    "print(f\"  10 forward passes: {time_optimized:.3f}s ({time_optimized/10:.3f}s each)\")\n",
    "\n",
    "# Speedup\n",
    "speedup = time_original / time_optimized\n",
    "print(f\"\\n‚úì Speedup: {speedup:.1f}x faster with optimization!\")\n",
    "\n",
    "print(\"\\nOptimizations applied:\")\n",
    "print(\"  ‚úì Disabled gradient computation\")\n",
    "print(\"  ‚úì Enabled cudnn benchmarking\")\n",
    "print(\"  ‚úì Set to eval mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Combined Optimization Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE OPTIMIZATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nOptimization Strategies:\")\n",
    "print(\"\\n1. Caching:\")\n",
    "print(\"   - Use case: Repeated explanations for same images\")\n",
    "print(\"   - Speedup: 10-50x\")\n",
    "print(\"   - Trade-off: Disk space\")\n",
    "print(\"\\n2. Batch Processing:\")\n",
    "print(\"   - Use case: Multiple images at once\")\n",
    "print(\"   - Speedup: 2-5x\")\n",
    "print(\"   - Trade-off: Memory usage\")\n",
    "print(\"\\n3. Model Optimization:\")\n",
    "print(\"   - Use case: All inference operations\")\n",
    "print(\"   - Speedup: 1.5-3x\")\n",
    "print(\"   - Trade-off: None (always recommended)\")\n",
    "print(\"\\n4. Profiling:\")\n",
    "print(\"   - Use case: Identifying bottlenecks\")\n",
    "print(\"   - Benefit: Targeted optimization\")\n",
    "print(\"   - Trade-off: Small overhead when enabled\")\n",
    "print(\"\\n‚úì Combined: Up to 100x speedup possible!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production Best Practices\n",
    "\n",
    "Deploying interpretations in production? Follow these guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Recommended Production Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example production configuration\n",
    "print(\"\"\"\n",
    "PRODUCTION SETUP CHECKLIST:\n",
    "\n",
    "‚úì 1. Model Optimization\n",
    "   model = optimize_for_inference(model, use_fp16=True)  # GPU only\n",
    "\n",
    "‚úì 2. Enable Caching\n",
    "   cache = ExplanationCache(\n",
    "       cache_dir='/var/cache/explanations',\n",
    "       max_size_mb=5000,  # 5GB\n",
    "       enabled=True\n",
    "   )\n",
    "\n",
    "‚úì 3. Batch Processing\n",
    "   processor = BatchProcessor(\n",
    "       model, explainer,\n",
    "       batch_size=32,  # Tune for your hardware\n",
    "       use_cuda=True\n",
    "   )\n",
    "\n",
    "‚úì 4. Performance Monitoring\n",
    "   profiler = PerformanceProfiler(enabled=True)\n",
    "   \n",
    "   with profiler.profile('request'):\n",
    "       explanation = generate_explanation(image)\n",
    "   \n",
    "   # Alert if slow\n",
    "   if profiler.get_stats()['request']['mean'] > 1.0:\n",
    "       log_warning('Slow explanation detected')\n",
    "\n",
    "‚úì 5. Error Handling\n",
    "   try:\n",
    "       heatmap = cache.get(image, method='gradcam')\n",
    "       if heatmap is None:\n",
    "           heatmap = explainer.explain(image)\n",
    "           cache.put(image, method='gradcam', explanation=heatmap)\n",
    "   except Exception as e:\n",
    "       log_error(f'Explanation failed: {e}')\n",
    "       # Fallback: return default or retry\n",
    "\n",
    "‚úì 6. Resource Limits\n",
    "   - Set memory limits for cache\n",
    "   - Monitor disk usage\n",
    "   - Implement request throttling\n",
    "   - Use async processing for slow methods\n",
    "\n",
    "‚úì 7. Logging & Monitoring\n",
    "   - Log cache hit rates\n",
    "   - Monitor explanation latency\n",
    "   - Track error rates\n",
    "   - Alert on anomalies\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Method Selection Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method selection guide\n",
    "method_guide = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'GradCAM',\n",
    "        'Speed': 'Fast',\n",
    "        'Quality': 'Good',\n",
    "        'Best For': 'General CNNs, Production',\n",
    "        'Limitation': 'CNN only'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'GradCAM++',\n",
    "        'Speed': 'Fast',\n",
    "        'Quality': 'Better',\n",
    "        'Best For': 'Multiple objects, CNNs',\n",
    "        'Limitation': 'CNN only'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Integrated Gradients',\n",
    "        'Speed': 'Slow',\n",
    "        'Quality': 'Excellent',\n",
    "        'Best For': 'Research, Pixel-level',\n",
    "        'Limitation': 'Computationally expensive'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'SmoothGrad',\n",
    "        'Speed': 'Slow',\n",
    "        'Quality': 'Very Good',\n",
    "        'Best For': 'Stable explanations',\n",
    "        'Limitation': 'Multiple forward passes'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'AttentionRollout',\n",
    "        'Speed': 'Fast',\n",
    "        'Quality': 'Good',\n",
    "        'Best For': 'Vision Transformers',\n",
    "        'Limitation': 'ViT only'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'AttentionFlow',\n",
    "        'Speed': 'Fast',\n",
    "        'Quality': 'Good',\n",
    "        'Best For': 'Vision Transformers',\n",
    "        'Limitation': 'ViT only'\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD SELECTION GUIDE\")\n",
    "print(\"=\"*80)\n",
    "print(method_guide.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"  ‚Ä¢ Production: GradCAM or GradCAM++ (fast, reliable)\")\n",
    "print(\"  ‚Ä¢ Research: Integrated Gradients or SmoothGrad (thorough)\")\n",
    "print(\"  ‚Ä¢ CNNs: GradCAM, GradCAM++, Integrated Gradients, SmoothGrad\")\n",
    "print(\"  ‚Ä¢ ViTs: AttentionRollout, AttentionFlow\")\n",
    "print(\"  ‚Ä¢ Real-time: GradCAM (fastest)\")\n",
    "print(\"  ‚Ä¢ Highest quality: Integrated Gradients (slowest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Common Pitfalls and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "COMMON PITFALLS AND SOLUTIONS:\n",
    "\n",
    "1. PITFALL: Slow explanations in production\n",
    "   SOLUTION: Enable caching, use GradCAM, optimize model\n",
    "\n",
    "2. PITFALL: Different explanations for same image\n",
    "   SOLUTION: Check if model is in eval mode, disable dropout\n",
    "\n",
    "3. PITFALL: Explanations look noisy\n",
    "   SOLUTION: Use SmoothGrad or GradCAM++ instead of raw gradients\n",
    "\n",
    "4. PITFALL: Out of memory errors\n",
    "   SOLUTION: Reduce batch size, use FP16, clear cache regularly\n",
    "\n",
    "5. PITFALL: Explanations don't match intuition\n",
    "   SOLUTION: Validate with metrics (deletion, insertion), try multiple methods\n",
    "\n",
    "6. PITFALL: Wrong target layer selected\n",
    "   SOLUTION: Use layer_name parameter or automatic detection\n",
    "\n",
    "7. PITFALL: Cache grows too large\n",
    "   SOLUTION: Set max_size_mb, monitor utilization, implement cleanup\n",
    "\n",
    "8. PITFALL: Metrics show poor explanation quality\n",
    "   SOLUTION: Try different methods, check if model is properly trained\n",
    "\n",
    "9. PITFALL: Interactive visualizations too large\n",
    "   SOLUTION: Reduce image resolution, limit number of methods\n",
    "\n",
    "10. PITFALL: Inconsistent results across runs\n",
    "    SOLUTION: Set random seed, check for model randomness (dropout, etc.)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complete Workflow Example\n",
    "\n",
    "Let's put it all together in a realistic workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_interpretation_workflow(\n",
    "    model,\n",
    "    image,\n",
    "    target_class=None,\n",
    "    enable_cache=True,\n",
    "    enable_profiling=True,\n",
    "    save_interactive=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete interpretation workflow demonstrating best practices.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to interpret\n",
    "        image: Input image\n",
    "        target_class: Target class (None = predicted class)\n",
    "        enable_cache: Whether to use caching\n",
    "        enable_profiling: Whether to profile performance\n",
    "        save_interactive: Whether to save interactive visualization\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results including explanation, metrics, and timings\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Setup\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPLETE INTERPRETATION WORKFLOW\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize components\n",
    "    explainer = GradCAM(model)\n",
    "    \n",
    "    if enable_cache:\n",
    "        cache = ExplanationCache(cache_dir=\"./workflow_cache\", max_size_mb=100)\n",
    "        print(\"‚úì Cache enabled\")\n",
    "    \n",
    "    if enable_profiling:\n",
    "        profiler = PerformanceProfiler(enabled=True)\n",
    "        print(\"‚úì Profiling enabled\")\n",
    "    \n",
    "    # 2. Generate Explanation\n",
    "    print(\"\\nStep 1: Generating explanation...\")\n",
    "    \n",
    "    if enable_profiling:\n",
    "        with profiler.profile(\"explanation\"):\n",
    "            if enable_cache:\n",
    "                heatmap = cache.get(image, method=\"gradcam\", target_class=target_class)\n",
    "                if heatmap is None:\n",
    "                    heatmap = explainer.explain(image, target_class=target_class)\n",
    "                    cache.put(image, method=\"gradcam\", explanation=heatmap, target_class=target_class)\n",
    "                    print(\"  Cache MISS - computed\")\n",
    "                else:\n",
    "                    print(\"  Cache HIT - loaded from cache\")\n",
    "            else:\n",
    "                heatmap = explainer.explain(image, target_class=target_class)\n",
    "    else:\n",
    "        heatmap = explainer.explain(image, target_class=target_class)\n",
    "    \n",
    "    results['heatmap'] = heatmap\n",
    "    print(\"‚úì Explanation generated\")\n",
    "    \n",
    "    # 3. Evaluate Quality\n",
    "    print(\"\\nStep 2: Evaluating explanation quality...\")\n",
    "    metrics = ExplanationMetrics(model, explainer)\n",
    "    \n",
    "    if enable_profiling:\n",
    "        with profiler.profile(\"metrics\"):\n",
    "            deletion_result = metrics.deletion(image, target_class=target_class, steps=10)\n",
    "            insertion_result = metrics.insertion(image, target_class=target_class, steps=10)\n",
    "    else:\n",
    "        deletion_result = metrics.deletion(image, target_class=target_class, steps=10)\n",
    "        insertion_result = metrics.insertion(image, target_class=target_class, steps=10)\n",
    "    \n",
    "    results['metrics'] = {\n",
    "        'deletion_auc': deletion_result['auc'],\n",
    "        'insertion_auc': insertion_result['auc']\n",
    "    }\n",
    "    \n",
    "    print(f\"  Deletion AUC: {deletion_result['auc']:.4f}\")\n",
    "    print(f\"  Insertion AUC: {insertion_result['auc']:.4f}\")\n",
    "    print(\"‚úì Metrics computed\")\n",
    "    \n",
    "    # 4. Visualize\n",
    "    print(\"\\nStep 3: Creating visualizations...\")\n",
    "    \n",
    "    # Static visualization\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    explainer.visualize(image, heatmap, alpha=0.6, title=\"Explanation\", ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"workflow_static.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  Static visualization saved: workflow_static.png\")\n",
    "    \n",
    "    # Interactive visualization\n",
    "    if save_interactive and INTERACTIVE_AVAILABLE:\n",
    "        viz = InteractiveVisualizer(model)\n",
    "        fig = viz.visualize_explanation(\n",
    "            image,\n",
    "            explainer,\n",
    "            target_class=target_class,\n",
    "            save_path=\"workflow_interactive.html\"\n",
    "        )\n",
    "        print(\"  Interactive visualization saved: workflow_interactive.html\")\n",
    "    \n",
    "    print(\"‚úì Visualizations created\")\n",
    "    \n",
    "    # 5. Performance Summary\n",
    "    if enable_profiling:\n",
    "        print(\"\\nStep 4: Performance summary...\")\n",
    "        profiler.print_stats()\n",
    "        results['profiling'] = profiler.get_stats()\n",
    "    \n",
    "    # 6. Cache Statistics\n",
    "    if enable_cache:\n",
    "        print(\"\\nCache statistics:\")\n",
    "        cache_stats = cache.stats()\n",
    "        print(f\"  Entries: {cache_stats['num_entries']}\")\n",
    "        print(f\"  Size: {cache_stats['total_size_mb']:.2f} MB\")\n",
    "        print(f\"  Utilization: {cache_stats['utilization']:.1%}\")\n",
    "        results['cache'] = cache_stats\n",
    "        \n",
    "        # Cleanup\n",
    "        cache.clear()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úì WORKFLOW COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run complete workflow\n",
    "workflow_results = complete_interpretation_workflow(\n",
    "    model,\n",
    "    test_image,\n",
    "    target_class=5,\n",
    "    enable_cache=True,\n",
    "    enable_profiling=True,\n",
    "    save_interactive=INTERACTIVE_AVAILABLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've learned the complete AutoTimm interpretation toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    TUTORIAL COMPLETE!                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "What You Learned:\n",
    "\n",
    "‚úì 1. INTERPRETATION METHODS (6 methods)\n",
    "     ‚Ä¢ GradCAM, GradCAM++\n",
    "     ‚Ä¢ Integrated Gradients, SmoothGrad\n",
    "     ‚Ä¢ AttentionRollout, AttentionFlow\n",
    "\n",
    "‚úì 2. QUALITY METRICS (6 metrics)\n",
    "     ‚Ä¢ Deletion, Insertion (faithfulness)\n",
    "     ‚Ä¢ Sensitivity-N (stability)\n",
    "     ‚Ä¢ Sanity checks (2)\n",
    "     ‚Ä¢ Pointing game (localization)\n",
    "\n",
    "‚úì 3. INTERACTIVE VISUALIZATIONS\n",
    "     ‚Ä¢ Plotly-based exploration\n",
    "     ‚Ä¢ Method comparisons\n",
    "     ‚Ä¢ HTML reports\n",
    "\n",
    "‚úì 4. PERFORMANCE OPTIMIZATION\n",
    "     ‚Ä¢ Caching (10-50x speedup)\n",
    "     ‚Ä¢ Batch processing (2-5x speedup)\n",
    "     ‚Ä¢ Model optimization (1.5-3x speedup)\n",
    "     ‚Ä¢ Profiling tools\n",
    "\n",
    "‚úì 5. PRODUCTION BEST PRACTICES\n",
    "     ‚Ä¢ Method selection\n",
    "     ‚Ä¢ Error handling\n",
    "     ‚Ä¢ Monitoring\n",
    "     ‚Ä¢ Common pitfalls\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "1. Try with your own model and data\n",
    "2. Experiment with different methods\n",
    "3. Evaluate explanations with metrics\n",
    "4. Deploy to production with optimizations\n",
    "5. Read the full documentation at: docs/user-guide/interpretation/\n",
    "\n",
    "Resources:\n",
    "\n",
    "‚Ä¢ Documentation: docs/\n",
    "‚Ä¢ Examples: examples/\n",
    "‚Ä¢ Tests: tests/test_interpretation*.py\n",
    "‚Ä¢ API Reference: https://autotimm.readthedocs.io/\n",
    "\n",
    "Questions? Issues?\n",
    "\n",
    "‚Ä¢ GitHub Issues: https://github.com/yourusername/autotimm/issues\n",
    "‚Ä¢ Documentation: https://autotimm.readthedocs.io/\n",
    "\n",
    "Happy Interpreting! üéâ\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
